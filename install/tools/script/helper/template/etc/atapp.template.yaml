<%!
    import common.project_utils as project
%>
atapp:
  # =========== bus configure ===========
  id: ${hex(project.get_server_id())}      # bus id
  name: "${project.get_server_name()}-${hex(project.get_server_id())}"  # name with id
  type_id: ${project.get_server_type_id()}      # server type id
  type_name: "${project.get_server_name()}"       # server type name
  area:
    zone_id: ${project.get_global_option('global', 'zone_id', 0)}
  hostname: "${project.get_hostname()[0]}"   # hostname, any host should has a unique name. if empty, we wil try to use the mac address
  metadata:
    labels:
      "deployment.environment": "${project.get_global_option('global', 'deployment_environment', '')}" # formal/dev/test/qa
  bus:
    listen:
% for bus_listen in project.get_server_atbus_listen():
      - ${bus_listen}
% endfor
    subnets:
% for bus_listen in project.get_server_subnets():
      - ${bus_listen}
% endfor
    proxy: ${project.get_server_proxy()} # atgateway must has parent node
    loop_times: 1000                   # max message number in one loop
    ttl: 16                            # max ttl when transfer messages
    backlog: 256                       # tcp backlog
    access_token_max_number: ${project.get_global_option('atsystem', 'access_token_max_number', '5')}
    access_tokens:
% for access_token in project.get_global_list('atsystem', 'access_tokens', ''):
      - ${access_token}
% endfor
    first_idle_timeout: 30s            # first idle timeout when have new connection(second)
    ping_interval: 8s                  # ping interval(second)
    retry_interval: 3s                 # retry interval when error happen(second)
    fault_tolerant: 2                  # how many errors at most to ignore, or it will kill the connection
    msg_size: 262144                   # max message size(256KB)
    recv_buffer_size: ${project.get_server_recv_buffer_size()} # recv channel size(2MB), will be used to initialize (shared) memory channel size
    send_buffer_size: ${project.get_server_send_buffer_size()} # send buffer size, will be used to initialize io_stream channel write queue
    send_buffer_number: 0              # send message number limit, will be used to initialize io_stream channel write queue, 0 for dynamic buffer

  # =========== upper configures can not be reload ===========
  # =========== timer ===========
  timer:
    tick_interval: 16ms # 32ms for tick active
    tick_round_timeout: 128ms
    stop_timeout: 10s # 10s for stop operation
    stop_interval: 256ms
    message_timeout: 8s
    initialize_timeout: 30s
    reserve_interval_min: 250us
    reserve_interval_max: 1s
    reserve_permille: 25
  # =========== log configure ===========
  log:
    level: ${project.get_log_level()}  # log active level(disable/disabled, fatal, error, warn/warning, info, notice, debug)
    category:
      - name: default
        index: 0
        prefix: "[Log %L][%F %T.%f][%s:%n(%C)]: " # log categorize 0's name = default
        stacktrace:
          min: error
          max: fatal
        sink:
          - type: file
            level:
              min: fatal
              max: warning
            rotate:
              number: 10
              size: 10485760 # 10MB
            file: "${project.get_log_dir()}/${project.get_server_full_name()}.error.%N.log"
            writing_alias: "${project.get_log_dir()}/${project.get_server_full_name()}.error.log"
            auto_flush: error
            flush_interval: 1s
          - type: file
            level:
              min: fatal
              max: debug
            rotate:
              number: 10
              size: 10485760 # 10MB
            file: "${project.get_log_dir()}/${project.get_server_full_name()}.all.%N.log"
            writing_alias: "${project.get_log_dir()}/${project.get_server_full_name()}.all.log"
            auto_flush: warning
            flush_interval: 1s
      - name: db
        index: 1
        prefix: "[Log %L][%F %T.%f]: " # log categorize 1's name = db
        stacktrace:
          min: disable
          max: disable
        sink:
          - type: file
            level:
              min: fatal
              max: debug
            rotate:
              number: 10
              size: 10485760 # 10MB
            file: "${project.get_log_dir()}/${project.get_server_full_name()}.db.%N.log"
            writing_alias: "${project.get_log_dir()}/${project.get_server_full_name()}.db.log"
            auto_flush: warning
            flush_interval: 1s
      - name: proto_stat
        index: 2
        prefix: "[%F %T.%f]: " # log categorize 2's name = proto_stat
        stacktrace:
          min: disable
          max: disable
        sink:
          - type: file
            level:
              min: fatal
              max: debug
            rotate:
              number: 10
              size: 20971520 ; 20MB
            file: "${project.get_log_dir()}/${project.get_server_full_name()}.pstat.%N.log"
            writing_alias: "${project.get_log_dir()}/${project.get_server_full_name()}.pstat.log"
            auto_flush: warning
            flush_interval: 1s
      - name: pay
        index: 3
        prefix: "[%F %T.%f]: " # log categorize 3's name = pay
        stacktrace:
          min: disable
          max: disable
        sink:
          - type: file
            level:
              min: fatal
              max: debug
            rotate:
              number: 10
              size: 20971520 ; 20MB
            file: "${project.get_log_dir()}/${project.get_server_full_name()}.pay.%N.log"
            writing_alias: "${project.get_log_dir()}/${project.get_server_full_name()}.pay.log"
            auto_flush: warning
            flush_interval: 1s
  # =========== etcd service for discovery ===========
  etcd:
% if project.get_etcd_client_urls():
    enable: true
% else:
    enable: false
% endif
    log:
      startup_level: debug
      level: info
      category:
        - name: etcd_default
          prefix: "[Log %L][%F %T.%f][%s:%n(%C)]: " # log categorize 0's name = etcd_default
          stacktrace:
            min: disable
            max: disable
          sink:
            - type: file
              level:
                min: fatal
                max: trace
              rotate:
                number: 10
                size: 10485760 # 10MB
              file: "${project.get_log_dir()}/${project.get_server_full_name()}.etcd.%N.log"
              writing_alias: "${project.get_log_dir()}/${project.get_server_full_name()}.etcd.log"
              auto_flush: info
              flush_interval: 1s # 1s (unit: s,m,h,d)
    hosts:
% for etcd_host in project.get_etcd_client_urls().split(','):
      - ${etcd_host}
% endfor
    path: ${project.get_server_or_global_option('etcd', 'path', '/atapp/services', 'SYSTEM_MACRO_CUSTOM_ETCD_PATH')}
    authorization: ${project.get_server_or_global_option('etcd', 'authorization', '', 'SYSTEM_MACRO_CUSTOM_ETCD_AUTHORIZATION')}
    # http:
    #   debug: false
    #   user_agent: ""
    #   proxy
    #   no_proxy
    #   proxy_user_name
    #   proxy_password
    ssl:
      enable_alpn: true
      verify_peer: false
      ssl_min_version: TLSv1.2
      # ssl_client_cert:       # CURLOPT_SSLCERT
      # ssl_client_cert_type:  # CURLOPT_SSLCERTTYPE: PEM or DER
      # ssl_client_key:        # CURLOPT_SSLKEY
      # ssl_client_key_type:   # CURLOPT_SSLKEYTYPE: PEM, DER or ENG
      # ssl_client_key_passwd: # CURLOPT_KEYPASSWD or CURLOPT_SSLCERTPASSWD
      # ssl_ca_cert:           # CURLOPT_CAINFO
      # ssl_proxy_cert:        # CURLOPT_PROXY_SSLCERT
      # ssl_proxy_cert_type:   # CURLOPT_PROXY_SSLCERTTYPE: PEM or DER
      # ssl_proxy_key:         # CURLOPT_PROXY_SSLKEY
      # ssl_proxy_key_type:    # CURLOPT_PROXY_SSLKEYTYPE: PEM, DER or ENG
      # ssl_proxy_key_passwd:  # CURLOPT_PROXY_KEYPASSWD or CURLOPT_PROXY_SSLCERTPASSWD
      # ssl_proxy_ca_cert:     # CURLOPT_PROXY_CAINFO
      # ssl_cipher_list:       # CURLOPT_SSL_CIPHER_LIST
      # ssl_cipher_list_tls13  # CURLOPT_TLS13_CIPHERS
    cluster:
      auto_update: ${project.get_server_or_global_option('etcd', 'cluster.auto_update', 'true', 'SYSTEM_MACRO_CUSTOM_ETCD_CLUSTER_AUTO_UPDATE')}       # update etcd cluster members interval
      update_interval: ${project.get_server_or_global_option('etcd', 'cluster.update_interval', '5m', 'SYSTEM_MACRO_CUSTOM_ETCD_CLUSTER_UPDATE_INTERVAL')}       # update etcd cluster members interval
      retry_interval: ${project.get_server_or_global_option('etcd', 'cluster.retry_interval', '1m', 'SYSTEM_MACRO_CUSTOM_ETCD_CLUSTER_RETRY_INTERVAL')}       # update etcd cluster retry interval
    keepalive:
      timeout: ${project.get_server_or_global_option('etcd', 'keepalive.timeout', '31s', 'SYSTEM_MACRO_CUSTOM_ETCD_KEEPALIVE_TIMEOUT')}            # expired timeout
      ttl: ${project.get_server_or_global_option('etcd', 'keepalive.ttl', '10s', 'SYSTEM_MACRO_CUSTOM_ETCD_KEEPALIVE_TTL')}                # renew ttl interval
      retry_interval: ${project.get_server_or_global_option('etcd', 'keepalive.retry_interval', '3s', 'SYSTEM_MACRO_CUSTOM_ETCD_KEEPALIVE_RETRY_INTERVAL')} # keepalive retry interval
    request:
      timeout: ${project.get_server_or_global_option('etcd', 'request.timeout', '15s', 'SYSTEM_MACRO_CUSTOM_ETCD_REQUEST_TIMEOUT')}             # timeout for etcd request
      initialization_timeout: ${project.get_server_or_global_option('etcd', 'request.initialization_timeout', '3s', 'SYSTEM_MACRO_CUSTOM_ETCD_INITIALIZATION_TIMEOUT')} # timeout for etcd initialization
      connect_timeout: ${project.get_server_or_global_option('etcd', 'request.connect_timeout', '0s', 'SYSTEM_MACRO_CUSTOM_ETCD_CONNECT_TIMEOUT')}             # timeout for etcd request connection
      dns_cache_timeout: ${project.get_server_or_global_option('etcd', 'request.dns_cache_timeout', '300s', 'SYSTEM_MACRO_CUSTOM_ETCD_DNS_CACHE_TIMEOUT')}             # timeout for dns cache of etcd request
      # dns_servers: ${project.get_server_or_global_option('etcd', 'request.dns_servers', '', 'SYSTEM_MACRO_CUSTOM_ETCD_DNS_SERVERS')}             # dns servers
    init:
      timeout: ${project.get_server_or_global_option('etcd', 'init.timeout', '5s', 'SYSTEM_MACRO_CUSTOM_ETCD_INIT_TIMEOUT')}                  # initialize timeout
      tick_interval: 256ms
    watcher:
      retry_interval: ${project.get_server_or_global_option('etcd', 'watcher.retry_interval', '15s', 'SYSTEM_MACRO_CUSTOM_ETCD_WATCHER_RETRY_INTERVAL')}       # retry interval watch when previous request failed
      request_timeout: ${project.get_server_or_global_option('etcd', 'watcher.request_timeout', '1h', 'SYSTEM_MACRO_CUSTOM_ETCD_WATCHER_REQUEST_TIMEOUT')}       # request timeout for watching
      get_request_timeout: ${project.get_server_or_global_option('etcd', 'watcher.get_request_timeout', '1h', 'SYSTEM_MACRO_CUSTOM_ETCD_WATCHER_GET_REQUEST_TIMEOUT')}
      startup_random_delay_min: ${project.get_server_or_global_option('etcd', 'watcher.startup_random_delay_min', '1h', 'SYSTEM_MACRO_CUSTOM_ETCD_WATCHER_STARTUP_RANDOM_DELAY_MIN')}
      startup_random_delay_max: ${project.get_server_or_global_option('etcd', 'watcher.startup_random_delay_max', '1h', 'SYSTEM_MACRO_CUSTOM_ETCD_WATCHER_STARTUP_RANDOM_DELAY_MAX')}
      by_id: true
      by_name: true
      # by_type_id: []
      # by_type_name: []
      # by_tag: []
    report_alive:
      by_id: ${project.get_server_or_global_option('etcd', 'report_alive.by_id', 'true', 'SYSTEM_MACRO_CUSTOM_ETCD_WATCHER_REPORT_BY_ID')}
      by_type: ${project.get_server_or_global_option('etcd', 'report_alive.by_type', 'true', 'SYSTEM_MACRO_CUSTOM_ETCD_WATCHER_REPORT_BY_TYPE')}
      by_name: ${project.get_server_or_global_option('etcd', 'report_alive.by_name', 'true', 'SYSTEM_MACRO_CUSTOM_ETCD_WATCHER_REPORT_BY_NAME')}
      by_tag:
% for tag in project.get_server_or_global_list('etcd', 'report_alive.by_tag', None, None):
        - ${tag}
% endfor
